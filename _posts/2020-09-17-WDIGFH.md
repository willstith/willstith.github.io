---
layout: post
title: Where Do I Go From Here?
---

With my 12 weeks of bootcamp behind me, the question now is, Where do I go from here? Next Monday I will not start the morning working with a partner on a coding problem. I won't have interactive lectures, and I won't be able to schedule one-on-one time with knowledgable instructors. I won't be set completely adrift, thanks to the fantastic network of fellow data scientists I've been building through Metis, as well as the curriculum and all my accumulated work I have to reference. But for the most part, I'm on my own starting from now. As a way of staking out my next steps towards finding a job and eventually greater success in data science, I'm writing this blog on the future work I plan on doing.

## Improve Existing Metis Projects

During my time at Metis, I created four independent projects covering a wide range of data science techniques. There are definitely improvements to be made to each, but I plan on focusing on my last two, largely because these were the topics that interested me the most.

### Jeopardy! Categories

My fourth project at Metis used NLP techniques to categorize questions and answers into more a more managable number of categories. The [data was found on Kaggle](https://www.kaggle.com/tunguz/200000-jeopardy-questions), where someone had scraped together a database of over 200,000 questions from [J! Archive](https://j-archive.com/). Each row of the data was a different question, along with the answer, category, point value, air date, round, and show number. Of course, questions on Jeopardy! already *have* categories, but they aren't categorized in any way that makes them usefully sorted for, say, someone practicing by going through all the old questions. I thought it would be useful to group the questions into common trivia categories, like sports or history or film. So, by performing NMF topic modeling with a TF-IDF vectorizer, I came up with 25 categories to bin each question into. In addition, I made a rudimentary application which allows players to cycle through random questions until getting one wrong, at which point you can serve up a question considered "most similar" to the one you'd gotten based on cosine distance of the topic vectors.

I was actually unaware when I first scoped out the project that one of my favorite Jeopardy! champions - Roger Craig, who happened to be getting his PhD in Computer Science at the time - had [done a similar, though more advanced, project of his own](https://vimeo.com/29001512) which helped him to get on the show and set what was at the time a single-day record of $77,000. As soon as I found this out, I wanted to incorporate some of his more advanced features into my project, but I did not have nearly enough time while I was busy digesting all that NLP material for the first time to do that. My future plans for this project are to get those features added in.

The primary advantages of Roger's project were the inclusion of the monetary value of the questions, the frequency of certain categories, and tracking a player's performance over time. As such, his model could estimate the most "valuable" questions to focus on (i.e. questions from categories that are more valuable on average, that appear more often than average, and that the player is worse at answering on average), as well as allow him to see where he was making the biggest gains. I plan to work on making these improvements to my project, and I would also like to make a more sophisticated application, ideally one which could be deployed publicly.

### Bird Image Classification

My [last blog post](https://willstith.github.io/2020/09/17/Bird-Up/) detailed my final project at Metis, which was a classifier for bird images. With it, I am able to sort my bird photos into specific folders corresponding to the bird identified in each image...with 61.9% accuracy across 36 species. Pretty good! But clearly it could do better. Previous groups have reported >90% accuracy across 200 species, so it's undeniably possible. These groups used more sophisticated convolutional neural network architectures, as well as augmentation of training images in some cases. My primary goal to improve this project is to implement Mask R-CNN, a relatively new model architecture which outperforms anything I incorporated. Mask R-CNN is able to detect objects in images and create a pixel-wise mask over that object, which tightly narrows the focus of later layers of a neural net. I spent much of the time working on this project trying to implement it, but alas, I am a noob, and it isn't so easy.

I'd also like to add more of my own bird photos and include more classes once I have sufficient number of photos of new species. The more training examples, the better! Of course, as my training data gets large enough, I'll need to think about ways to speed up the model (it already takes several seconds to sort each image...).

Lastly, I'd like to add an additional step to the program where photos with no bird at all are sorted into a separate folder. This may require the use of Mask R-CNN, but I think there are other, perhaps less effective, ways I could do it. This was another thing I tried to get working before the project due date, but was unable. My initial idea was to use predictions of another model pre-trained on a "birds" class as a way of filtering out the images that don't contain one. But ImageNet appears to only have certain specific species labelled, and even by grouping those together, the accuracy wasn't impressive. Not even worth incorporating for the time being.

## Future Project Ideas

When deciding on whether to pursue project ideas I have in the coming months, I have three criteria I want to consider:
* Does it involve techniques not seen in my previous projects?
* Does it accomplish something useful or interesting?
* Am I interested in the subject matter?

On the first point, Tableau immediately comes to mind. I used a little Tableau as part of the Metis curriculum, and I was seriously impressed by its functionalities, especially with location data. Unfortunately, using it was never a high enough priority for my projects (or simply didn't apply to the project), so my portfolio doesn't demonstrate my ability to use this common visualization tool. I was often impressed by the Tableau visualizations seen in my peers' presentations, and I'm sure employers would be similar impressed to see deft usage of it in my project portfolio. The other techniques that I missed out on using were ones working with big data and cluster computing. I am seeing these things referenced pretty frequently in job descriptions, and demonstrating my ability to manage big data could be key to landing certain jobs.

My first two Metis projects, predicting board game complexity and classifying wine as "fine" or not, weren't especially useful projects. You could say I was moderately interested in the results of the board game project, but the wine one was the most purely demonstrative project I did. There is very little practical use of that project, as its training data came from a single wine style, and its features were obscure physicochemical properties I'll be unlikely to ever have at the ready to plug in. This did not help with the project motivation, and parts of it became more of a chore than anything. Without such a stringent time constraint, I should be able to better scope out projects going forward so that whatever I spend my time on, there will be a useful end product.

Conversely, what made my projects enjoyable, even fun, was having a real interest in the subject matter. This is probably what made the early board game project more enjoyable than the wine project (that, plus it turns out I quite liked web scraping). As mentioned above, it's also what will keep me returning to a project to make improvements over time. I want to improve my Jeopardy! categorizer project not only because I need data science practice, but also because **I want to get on Jeopardy!** Turns out data science can be useful. Who knew. Same goes for my bird classifier, which I *know* I'll be working on again soon.



I plan on taking next week off from data science project work. A well-earned break, if you ask me. After that, time to get a job. And with so much more data science to learn, I'll definitely have my work cut out for me.

Catch you later on down the trail.



![sam_elliott_dude](https://media1.tenor.com/images/83e9f264560cb0f7347e86610d9fb318/tenor.gif?itemid=4268615)
