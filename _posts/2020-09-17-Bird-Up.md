---
layout: post
title: Classifying Bird Images Using CNNs and Transfer Learning
---

![](link to bird image)

### Introduction

My name's Will (as you can tell by the name of the blog) and I'm from Chicago. Over the past 12 weeks, I've probably learned more than during any 12 week stretch in my life. You see, around January I made the decision to switch career trajectories from neuroscience academia to data science, so I applied to [Metis](https://www.thisismetis.com/), a 12 week data science bootcamp with a location here in Chicago. The original plan was to be in-person, but as pandemic lockdowns went into effect, it became clear we would need to shift to remote learning. As I am wont to do, I picked up a new hobby during this time: birding!

![cedarwaxwing]({{ site.url }}/images/DSC_1822.JPG)

More specifically, bird photography. With plenty of time and surrounded by nature, I quickly amassed over 1000 pictures, and I was eager to share my best shots with my friends and family. But this wasn't easy with so many pictures. I'd often know what bird species I wanted to show someone, but I couldn't remember where in my entire catalog of pictures to find images of that particular species. Wouldn't it be nice if I could automatically sort my photos into folders specific to the species in the photo? Unsurprisingly, such an obscure tool didn't seem available to download anywhere. Good thing I was about to join that data science bootcamp...

My mid-August, after 8 weeks at Metis, I decided I would tackle the problem myself for my final passion project. At this point, I only had about two lectures worth of image analysis knowledge under my belt. Suffice it to say I did not really know what I was getting myself into.

### Fine-Grain Image Analysis

The problem I was stumbling into is called fine-grain image analysis, as contrasted with coarse-grain image analysis. Coarse-grain image classification would involve distinguishing between different classes which don't share many visual features (e.g. cars vs. people vs. buildings). Fine-grain image classification, on the other hand, involves distinguishing between different classes which *do* share lots of visual features. In my case, all birds have a beak and two wings and two legs, and most species just generally have similar body forms. But not only do different bird species look a lot like one another - often individuals of the same species look remarkably different from one another. Here's an example:

![starling_cowbird]({{ site.url }}/images/fine_grain_example.png)

Lots of variation *within* classes and lots of overlap *between* classes. It turns out birds are incredibly hard to classify. I spent the bulk of the first week on this project just reading papers on the various neural net model architectures that perform the best at the task of classifying birds by species. Practically all of them train and score their models using the [CUB 200-2011 dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html), which is a dataset of 11,788 bird images labeled into 200 different classes (aka species). This project wouldn't have been possible without either this dataset or painstaking manual labeling of my own images. I am grateful to have the former. To enhance accuracy and reduce computing complexity, I only dealt with the 36 species I had sighted in my area since March (fun fact: I've been keeping track of the bird species I see), and I supplemented some of the training classes with my own images. Classes were very well balanced, with right around 60 images per species. The dataset also includes plenty of extra files including bounding boxes for birds in each image, and attributes such as "has yellow beak". When I first set out to build my model, I was very distracted by all these extra files. I'm still not completely sure how they are to be used, but the impression I've gotten is that modern techniques do away with the strenuous manual "parts" labeling, and bounding boxes can be created separately using certain pretrained models.


### Building My Own Models

So I had the data, and I had a goal in mind: organize my bird pictures. What I didn't yet have was a plan. Inevitably, every time I attempted to implement one of the cutting-edge classification techniques, like [Mask R-CNN](https://github.com/matterport/Mask_RCNN), I got overwhelmed and failed to get to the point where my model was spitting out actual results. So I decided to make a simple binary classifier that would technically *work* even if it had a terrible accuracy score, just as a starting off point. By using [Keras'](https://keras.io/) functional model API, I constructed a convolutional neural network to distinguish between cedar waxwings (one of my favorite birds, the pretty one in the image at top) and red-wing blackbirds (one of my *least* favorite birds, territorial jerks who swoop at my head while I'm biking) which indeed achieved a terrible accuracy score, not much better than chance. But this was a start. I gradually made adjustments and added new classes to the model. One idea I had at this point was to group similar-looking bird species into superclasses, or "types". So I had a single class for the multiple species of woodpeckers, another for the multiple species of wrens, etc. I ended up with 8 "types", and was able to bump the model accuracy up to ~33% for this classification. At this point, I knew I needed to incorporate transfer learning to meaningfully improve my score.

Lo and behold, pre-trained base model the bottom of my model immediately improved my score. I tried VGG16 (pre-trained on ImageNet) and MobileNetV2 (also ImageNet), the latter of which performed best. The final model, with just a single additional output layer, achieved 88.5% accuracy on the 8 "types" classification task and a 61.9% accuracy on the 36 species, which I consider to be high enough to use over the "types" classifier. It's worth noting that wrong guesses tended toward similar-looking species, as can be seen by examining the confusion matrix I obtained by testing the final model. Here was the most common mistake the model made, which it made 8 times:

![confusion_matrix1]({{ site.url }}/images/birds_confusion_matrix1)

Maybe the training images didn't show great examples of the tops of these birds heads, where my human eyes detect the most distinguishing feature.

And here was another most common mistake, made 6 times:

![confusion_matrix2]({{ site.url }}/images/birds_confusion_matrix2)

These two species are notoriously difficult even for knowledgable human birders to distinguish, so it was unsurprising to me that the model only guessed correct between the two 7 out of 14 times. There's a lot more to explore in this confusion matrix, and I'll be consulting it as I think of more specific ways to improve the model, likely by adding training images.

### Using the Final Model

Now that I had a model performing to my satisfaction, it was time to write a program that would use that model to sort my bird photos into folders for each species. This part was relatively simple and mostly involved using python's [os module](https://docs.python.org/3/library/os.html) to move things around in my file system. When I run the script, all the images in my *unsorted_birds_pics* folder are run through the model and moved to the appropriate *[species name]* folder based on the model's prediction...well, appropriate 61.9% of the time.

### Conclusions

This was easily my favorite data science project I've worked on, and it makes me really excited to learn more about neural nets, in particular, CNNs. It was the first time I used data science to solve a genuine problem of mine, which is encouraging as I think about delving into future projects. The most challenging aspect was getting started with the actual code. My reading on the topics involved led me to think I would never see decent model performance on even simpler tasks without incorporating some of the highly advanced methods, and I underestimated the difficulty I would have in following along with explanations of these advanced methods. While there are many improvements I plan on making to this project over time, I will save that discussion for my next blog post. This project definitely made the Metis experience end on a high note for me and excited about my future in data science.
